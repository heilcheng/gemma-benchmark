models:
  phi-3-mini:
    type: huggingface
    model_id: microsoft/Phi-3-mini-4k-instruct
    size: 3.8B
    quantization: true
    cache_dir: cache/models
  phi-2:
    type: huggingface
    model_id: microsoft/Phi-2
    size: 2.7B
    quantization: true
    cache_dir: cache/models
  qwen2-1.5b:
    type: huggingface
    model_id: Qwen/Qwen2-1.5B
    size: 1.5B
    quantization: true
    cache_dir: cache/models
  qwen2-7b:
    type: huggingface
    model_id: Qwen/Qwen2-7B
    size: 7B
    quantization: true
    cache_dir: cache/models
  mistral-7b:
    type: huggingface
    model_id: mistralai/Mistral-7B-v0.1
    size: 7B
    quantization: true
    cache_dir: cache/models
  llama2-7b:
    type: huggingface
    model_id: meta-llama/Llama-2-7b-chat-hf
    size: 7B
    quantization: true
    cache_dir: cache/models
  gemma-2b:
    type: huggingface
    model_id: google/gemma-2b-it
    size: 2B
    quantization: true
    cache_dir: cache/models
tasks:
  mmlu:
    type: mmlu
    subset: all
    shot_count: 5
    temperature: 0.0
  gsm8k:
    type: gsm8k
    shot_count: 5
    use_chain_of_thought: true
  humaneval:
    type: humaneval
    shot_count: 0
    temperature: 0.2
  arc:
    type: arc
    shot_count: 3
    temperature: 0.0
  truthfulqa:
    type: truthfulqa
    shot_count: 0
    temperature: 0.0
evaluation:
  runs: 3
  batch_size: auto
  statistical_tests: true
output:
  path: benchmarks_output
  visualize: true
  export_formats:
  - json
  - csv
  - html
hardware:
  device: auto
  precision: float16
  quantization: true
